# 手动修改训练参数的方法

## 概述

除了命令行参数，您还可以通过以下几种方式手动修改训练参数：

## 方法1：直接在脚本中修改

在 `grpo_vlm_2.py` 脚本中，我已经添加了手动修改参数的代码段：

```python
if __name__ == "__main__":
    parser = TrlParser((ScriptArguments, GRPOConfig, ModelConfig, DataArguments))
    script_args, training_args, model_args, data_args = parser.parse_args_and_config()

    # ================
    # 手动修改训练参数
    # ================
    # 批次大小相关
    training_args.per_device_train_batch_size = 2
    training_args.gradient_accumulation_steps = 4
    training_args.num_generations = 4
    
    # 学习率相关
    training_args.learning_rate = 2e-5
    training_args.warmup_steps = 100
    training_args.lr_scheduler_type = "cosine"
    
    # 训练步数
    training_args.max_steps = 2000
    training_args.save_steps = 500
    training_args.eval_steps = 250
    
    # 其他参数
    training_args.logging_steps = 10
    training_args.save_strategy = "steps"
    training_args.evaluation_strategy = "steps"
    training_args.load_best_model_at_end = True
    training_args.metric_for_best_model = "eval_loss"
    
    # GRPO 特定参数
    training_args.beta = 0.1
    training_args.epsilon = 0.2
    training_args.loss_type = "dapo"
    training_args.scale_rewards = "group"
    
    # 生成参数
    training_args.max_prompt_length = 2048
    training_args.max_completion_length = 512
    training_args.temperature = 1.0
    training_args.top_p = 0.9
```

## 方法2：使用 Python 配置文件

### 创建配置文件 `training_config.py`

```python
# 训练参数配置
TRAINING_CONFIG = {
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 4,
    "num_generations": 4,
    "learning_rate": 2e-5,
    "warmup_steps": 100,
    "lr_scheduler_type": "cosine",
    "max_steps": 2000,
    "save_steps": 500,
    "eval_steps": 250,
    "logging_steps": 10,
    "save_strategy": "steps",
    "evaluation_strategy": "steps",
    "load_best_model_at_end": True,
    "metric_for_best_model": "eval_loss",
    "beta": 0.1,
    "epsilon": 0.2,
    "loss_type": "dapo",
    "scale_rewards": "group",
    "max_prompt_length": 2048,
    "max_completion_length": 512,
    "temperature": 1.0,
    "top_p": 0.9,
}
```

### 在脚本中使用配置文件

```python
# 在脚本中添加以下代码
import sys
sys.path.append('/home/lujunxi57/trl')
from training_config import TRAINING_CONFIG

# 应用配置
for key, value in TRAINING_CONFIG.items():
    setattr(training_args, key, value)
```

## 方法3：使用 JSON 配置文件

### 创建 JSON 配置文件 `training_config.json`

```json
{
  "training_args": {
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 4,
    "num_generations": 4,
    "learning_rate": 2e-5,
    "warmup_steps": 100,
    "lr_scheduler_type": "cosine",
    "max_steps": 2000,
    "save_steps": 500,
    "eval_steps": 250,
    "logging_steps": 10,
    "save_strategy": "steps",
    "evaluation_strategy": "steps",
    "load_best_model_at_end": true,
    "metric_for_best_model": "eval_loss",
    "beta": 0.1,
    "epsilon": 0.2,
    "loss_type": "dapo",
    "scale_rewards": "group",
    "max_prompt_length": 2048,
    "max_completion_length": 512,
    "temperature": 1.0,
    "top_p": 0.9
  }
}
```

### 在脚本中使用 JSON 配置

```python
import json

def load_config_from_json(config_path: str):
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def apply_config_to_args(training_args, config):
    if "training_args" in config:
        for key, value in config["training_args"].items():
            if hasattr(training_args, key):
                setattr(training_args, key, value)

# 使用配置
config = load_config_from_json("training_config.json")
apply_config_to_args(training_args, config)
```

## 方法4：使用环境变量

```python
import os

# 从环境变量读取参数
training_args.per_device_train_batch_size = int(os.getenv("BATCH_SIZE", "2"))
training_args.learning_rate = float(os.getenv("LEARNING_RATE", "2e-5"))
training_args.max_steps = int(os.getenv("MAX_STEPS", "2000"))
```

## 方法5：条件参数设置

```python
# 根据条件设置不同的参数
if model_args.model_name_or_path == "Qwen/Qwen2.5-VL-3B-Instruct":
    training_args.per_device_train_batch_size = 1
    training_args.gradient_accumulation_steps = 8
    training_args.learning_rate = 1e-5
elif model_args.model_name_or_path == "HuggingFaceTB/SmolVLM2-2.2B-Instruct":
    training_args.per_device_train_batch_size = 2
    training_args.gradient_accumulation_steps = 4
    training_args.learning_rate = 2e-5
```

## 参数优先级

参数设置的优先级（从高到低）：

1. **脚本中直接修改** - 最高优先级
2. **命令行参数** - 中等优先级
3. **配置文件** - 较低优先级
4. **默认值** - 最低优先级

## 常用参数说明

### 批次大小相关
- `per_device_train_batch_size`: 每个设备的批次大小
- `gradient_accumulation_steps`: 梯度累积步数
- `num_generations`: 每个提示的生成数量

### 学习率相关
- `learning_rate`: 学习率
- `warmup_steps`: 预热步数
- `lr_scheduler_type`: 学习率调度器类型

### 训练控制
- `max_steps`: 最大训练步数
- `num_train_epochs`: 训练轮数
- `save_steps`: 保存检查点的步数
- `eval_steps`: 评估的步数

### GRPO 特定参数
- `beta`: KL 系数
- `epsilon`: 裁剪参数
- `loss_type`: 损失类型
- `scale_rewards`: 奖励缩放策略

## 使用建议

1. **开发阶段**: 使用脚本中直接修改，便于调试
2. **实验阶段**: 使用配置文件，便于管理不同实验
3. **生产阶段**: 使用命令行参数，便于自动化部署

## 示例：完整的参数修改

```python
# 在脚本中添加完整的参数修改示例
def setup_training_parameters(training_args, model_args, data_args):
    """设置训练参数"""
    
    # 基础训练参数
    training_args.per_device_train_batch_size = 2
    training_args.gradient_accumulation_steps = 4
    training_args.num_generations = 4
    
    # 学习率设置
    training_args.learning_rate = 2e-5
    training_args.warmup_steps = 100
    training_args.lr_scheduler_type = "cosine"
    training_args.weight_decay = 0.01
    
    # 训练控制
    training_args.max_steps = 2000
    training_args.save_steps = 500
    training_args.eval_steps = 250
    training_args.logging_steps = 10
    
    # 保存和评估策略
    training_args.save_strategy = "steps"
    training_args.evaluation_strategy = "steps"
    training_args.load_best_model_at_end = True
    training_args.metric_for_best_model = "eval_loss"
    
    # GRPO 特定参数
    training_args.beta = 0.1
    training_args.epsilon = 0.2
    training_args.loss_type = "dapo"
    training_args.scale_rewards = "group"
    
    # 生成参数
    training_args.max_prompt_length = 2048
    training_args.max_completion_length = 512
    training_args.temperature = 1.0
    training_args.top_p = 0.9
    training_args.top_k = 50
    
    # 模型参数
    model_args.model_name_or_path = "Qwen/Qwen2.5-VL-3B-Instruct"
    model_args.dtype = "bfloat16"
    model_args.output_dir = "grpo-Qwen2.5-VL-3B-Instruct"
    
    # 数据参数
    data_args.dataset_path = "./aokvqa_trl_data"
    data_args.train_split = "train"
    data_args.test_split = "validation"
    data_args.streaming = False
    data_args.max_image_size = 1024

# 在 main 函数中调用
if __name__ == "__main__":
    parser = TrlParser((ScriptArguments, GRPOConfig, ModelConfig, DataArguments))
    script_args, training_args, model_args, data_args = parser.parse_args_and_config()
    
    # 设置参数
    setup_training_parameters(training_args, model_args, data_args)
    
    # 继续训练...
```
